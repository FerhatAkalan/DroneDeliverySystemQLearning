| Language | [English](#english)  | [TÃ¼rkÃ§e](#tÃ¼rkÃ§e) |
|-----------|-------------|---------|

## <a name="english"></a>

# ğŸš Drone Delivery System with Q-Learning

<div align="center">
  <p><em>Intelligent Package Delivery System with Reinforcement Learning</em></p>
</div>

---

## ğŸ“– About the Project

This project is an intelligent drone simulator that optimizes urban package deliveries using the **Reinforcement Learning (Q-Learning)** algorithm. Drones pick up packages from the cargo depot and learn the most efficient routes to deliver them to multiple delivery points.

### ğŸ¯ Project Goals
- Simulate real-world logistics problems
- Demonstrate practical application of the Q-Learning algorithm
- Observe the learning process with an interactive visual interface
- Experiment with training parameters to achieve the best results

## âœ¨ Features

- ğŸ¤– **Q-Learning Algorithm** with adjustable hyperparameters
- ğŸ® **Interactive Simulation** with real-time animations  
- ğŸ¯ **Manual & AI Modes** - Control drone or watch AI performance
- ğŸ’¾ **Model Management** - Save/load trained Q-tables
- ğŸ”‹ **Battery System** with energy costs for different actions

### ğŸ“Š Simulation Details
- ğŸŸ¢ **Cargo Depot**: Center where packages are picked up
- ğŸ”´ **Delivery Points**: Randomly placed target locations (1-3)
- ğŸ”µ **Drone**: Intelligent agent (battery, cargo status display)
- ğŸ”‹ **Battery Management**: Different energy costs for movement, takeoff, landing

### ğŸ’¾ Model Management
- **Save/Load Q-Table**: Store trained models
- **Training Statistics**: Track reward and steps per episode
- **Speed Settings**: Control training and simulation speeds

## ğŸ› ï¸ Technology Stack

- **Python 3.10+** - Main programming language
- **PyQt5** - GUI framework  
- **NumPy** - Numerical computations

## ğŸš€ Installation

```bash
# Python 3.10 or higher is required
python --version
# 1. Clone the Project
git clone https://github.com/FerhatAkalan/DroneDeliverySystemQLearning.git
cd DroneDeliverySystemQLearning
# 2. Install Dependencies
pip install PyQt5 numpy
# 3. Start the Simulator
python drone_delivery_system_q_learning.py
```

## ğŸ¯ Usage

### ğŸ“ Model Training
1. **Set Parameters**:
   - Grid size (3x3 - 7x7)
   - Learning rate (Alpha): 0.01 - 1.0
   - Discount factor (Gamma): 0.1 - 0.999
   - Exploration rate (Epsilon): 0.1 - 1.0

2. **Select Training Mode**:
   - **Fast**: Fast training in visual interface
   - **Human**: Step-by-step visual tracking

3. **Start Training**: Click the "ğŸš€ Start Training" button

### ğŸ¤– AI Demo
1. After training, use the "ğŸ¤– Play with AI" button
2. Watch the trained drone's performance in real time
3. You can adjust the simulation speed

## ğŸ§  Q-Learning Algorithm

### ğŸ”„ Action Space
| Action | Description | Condition |
|--------|-------------|-----------|
| `0` â¬‡ï¸ | Move down | Drone must be flying |
| `1` â¡ï¸ | Move right | Drone must be flying |
| `2` â¬†ï¸ | Move up | Drone must be flying |
| `3` â¬…ï¸ | Move left | Drone must be flying |
| `4` ğŸ“¦ | Pick/Drop cargo | Drone must be on the ground |
| `5` ğŸ›«ğŸ›¬ | Takeoff/Land | Always |

### ğŸ† Reward System

#### âœ… Positive Rewards
- **Pick up cargo**: +50 points
- **Successful delivery**: +200 points
- **Task completion**: +200 + battery bonus
- **Approaching target**: +5 points
- **Correct action at correct position**: +10 points

#### âŒ Penalties
- **Invalid action**: -2 to -30 points
- **Battery depletion**: -100 points
- **Timeout**: -50 points

## ğŸ¥ Project Video
https://github.com/user-attachments/assets/dc8752a9-d821-4c75-901b-993b0077d4b4

## ğŸ”¬ Experimental Results

### ğŸ“Š Training Performance
- **Grid Size**: 5x5
- **Training**: 50K episodes, 85%+ success rate

### ğŸ“ˆ Learning Curve
As training progresses, drone performance increases significantly:
- First 1000 episodes: Random behavior
- 1000-3000 episodes: Learning basic strategy
- 3000+ episodes: Optimized route planning

## ğŸ¤ Contributing

If you want to contribute to this project:

1. **Fork** it
2. **Create a feature branch** (`git checkout -b feature/NewFeature`)
3. **Commit** (`git commit -am 'Add new feature'`)
4. **Push** (`git push origin feature/NewFeature`)
5. **Create a Pull Request**

### ğŸ’¡ Contribution Areas

| ğŸš€ Feature | ğŸ“ Description | ğŸ¯ Difficulty |
|-----------|---------------|--------------|
| **Obstacle System** | Obstacles and wind effect in grid | ğŸŸ¡ Medium |
| **Multi Drone** | Multiple drones at the same time | ğŸ”´ Hard |
| **Deep Q-Learning** | Neural network-based learning | ğŸ”´ Hard |
| **3D Visualization** | 3D environment | ğŸŸ¡ Medium |
| **Real-Time Statistics** | Matplotlib integration | ğŸŸ¢ Easy |
| **Sound Effects** | Drone sounds and feedback | ğŸŸ¢ Easy |

---

<div align="center">
  <h3>â­ If you like the project, don't forget to give a star! â­</h3>
  <p>If you have any questions, you can <a href="https://github.com/FerhatAkalan/DroneDeliverySystemQLearning/issues">open an issue</a>.</p>
  
  **ğŸš Happy Coding! ğŸš**
  
  <sub>Made with â¤ï¸ by Ferhat Akalan</sub>
</div>

---

</br>

---

## <a name="tÃ¼rkÃ§e"></a>

# ğŸš Q-Learning ile Drone Teslimat Sistemi

<div align="center">
  <p><em>PekiÅŸtirmeli Ã–ÄŸrenme ile AkÄ±llÄ± Paket Teslimat Sistemi</em></p>
</div>

---

## ğŸ“– Proje HakkÄ±nda

Bu proje, **PekiÅŸtirmeli Ã–ÄŸrenme (Q-Learning)** algoritmasÄ± kullanarak ÅŸehir iÃ§i paket teslimatlarÄ±nÄ± optimize eden akÄ±llÄ± bir dron simÃ¼latÃ¶rÃ¼dÃ¼r. Dronlar, kargo deposundan paketleri alÄ±p birden fazla teslimat noktasÄ±na en verimli rotalarÄ± Ã¶ÄŸrenerek ulaÅŸtÄ±rÄ±rlar.

### ğŸ¯ Proje Hedefleri
- GerÃ§ek dÃ¼nya lojistik problemlerini simÃ¼le etmek
- Q-Learning algoritmasÄ±nÄ±n pratik uygulamasÄ±nÄ± gÃ¶stermek  
- Ä°nteraktif gÃ¶rsel arayÃ¼z ile Ã¶ÄŸrenme sÃ¼recini gÃ¶zlemlemek
- EÄŸitim parametrelerini deneyimleyerek en iyi sonuÃ§larÄ± elde etmek          

## âœ¨ Ã–zellikler

- ğŸ¤– **Q-Learning AlgoritmasÄ±** ayarlanabilir hiperparametrelerle
- ğŸ® **Ä°nteraktif SimÃ¼lasyon** gerÃ§ek zamanlÄ± animasyonlarla
- ğŸ¯ **Manuel & AI ModlarÄ±** - Drone kontrolÃ¼ veya AI performansÄ± izleme
- ğŸ’¾ **Model YÃ¶netimi** - EÄŸitilmiÅŸ Q-tablolarÄ±nÄ± kaydetme/yÃ¼kleme
- ğŸ”‹ **Batarya Sistemi** farklÄ± eylemler iÃ§in enerji maliyetleri

### ğŸ“Š SimÃ¼lasyon DetaylarÄ±
- ğŸŸ¢ **Kargo Deposu**: Paketlerin alÄ±ndÄ±ÄŸÄ± merkez
- ğŸ”´ **Teslimat NoktalarÄ±**: Rastgele yerleÅŸtirilen hedef lokasyonlar (1-3 adet)
- ğŸ”µ **Drone**: AkÄ±llÄ± ajan (batarya, kargo durumu gÃ¶sterimi)
- ğŸ”‹ **Batarya YÃ¶netimi**: Hareket, kalkÄ±ÅŸ, iniÅŸ iÃ§in farklÄ± enerji maliyetleri

## ğŸ› ï¸ Teknoloji Stack

- **Python 3.10+** - Ana programlama dili
- **PyQt5** - GUI framework
- **NumPy** - SayÄ±sal hesaplamalar

## ğŸš€ Kurulum

```bash
# Python 3.10 veya Ã¼zeri gereklidir
python --version
# 1. Projeyi KlonlayÄ±n
git clone https://github.com/FerhatAkalan/DroneDeliverySystemQLearning.git
cd DroneDeliverySystemQLearning
# 2. BaÄŸÄ±mlÄ±lÄ±klarÄ± YÃ¼kleyin
pip install PyQt5 numpy
# 3. SimÃ¼latÃ¶rÃ¼ BaÅŸlatÄ±n
python drone_delivery_system_q_learning.py
```

## ğŸ¯ KullanÄ±m

### ğŸ“ Model EÄŸitimi
1. **Parametreleri AyarlayÄ±n**:
   - Grid boyutu (3x3 - 7x7)
   - Learning rate (Alpha): 0.01 - 1.0
   - Discount factor (Gamma): 0.1 - 0.999
   - Exploration rate (Epsilon): 0.1 - 1.0

2. **EÄŸitim Modunu SeÃ§in**:
   - **Fast**: GÃ¶rsel arayÃ¼zde hÄ±zlÄ± eÄŸitim
   - **Human**: AdÄ±m adÄ±m gÃ¶rsel takip

3. **EÄŸitimi BaÅŸlatÄ±n**: "ğŸš€ EÄŸitimi BaÅŸlat" butonuna tÄ±klayÄ±n

### ğŸ¤– AI Demo
1. EÄŸitim tamamlandÄ±ktan sonra "ğŸ¤– AI ile Oyna" butonunu kullanÄ±n
2. EÄŸitilmiÅŸ dronun performansÄ±nÄ± gerÃ§ek zamanlÄ± izleyin
3. SimÃ¼lasyon hÄ±zÄ±nÄ± ayarlayabilirsiniz

## ğŸ§  Q-Learning AlgoritmasÄ±

### ğŸ”„ Eylem UzayÄ±
| Eylem | AÃ§Ä±klama | KoÅŸul |
|-------|----------|-------|
| `0` â¬‡ï¸ | AÅŸaÄŸÄ± hareket | Drone havada olmalÄ± |
| `1` â¡ï¸ | SaÄŸa hareket | Drone havada olmalÄ± |
| `2` â¬†ï¸ | YukarÄ± hareket | Drone havada olmalÄ± |
| `3` â¬…ï¸ | Sola hareket | Drone havada olmalÄ± |
| `4` ğŸ“¦ | Kargo al/bÄ±rak | Drone yerde olmalÄ± |
| `5` ğŸ›«ğŸ›¬ | KalkÄ±ÅŸ/Ä°niÅŸ | Her zaman |

### ğŸ† Ã–dÃ¼l Sistemi

#### âœ… Pozitif Ã–dÃ¼ller
- **Kargo alma**: +50 puan
- **BaÅŸarÄ±lÄ± teslimat**: +200 puan
- **GÃ¶rev tamamlama**: +200 + batarya bonusu
- **Hedefe yaklaÅŸma**: +5 puan
- **DoÄŸru konumda eylem**: +10 puan

#### âŒ Cezalar
- **GeÃ§ersiz eylem**: -2 ile -30 puan arasÄ±
- **Batarya bitimi**: -100 puan
- **Zaman aÅŸÄ±mÄ±**: -50 puan

## ğŸ¥ Proje Videosu
https://github.com/user-attachments/assets/dc8752a9-d821-4c75-901b-993b0077d4b4

## ğŸ”¬ Deneysel SonuÃ§lar

### ğŸ“Š EÄŸitim PerformansÄ±
- **Grid Boyutu**: 5x5
- **EÄŸitim**: 50K episode, %85+ baÅŸarÄ± oranÄ±

### ğŸ“ˆ Ã–ÄŸrenme EÄŸrisi
EÄŸitim ilerledikÃ§e dronun performansÄ± belirgin ÅŸekilde artar:
- Ä°lk 1000 episode: Rastgele davranÄ±ÅŸ
- 1000-3000 episode: Temel strateji Ã¶ÄŸrenme
- 3000+ episode: Optimize edilmiÅŸ rota planlama

## ğŸ¤ KatkÄ±da Bulunma

Bu projeye katkÄ±da bulunmak istiyorsanÄ±z:

1. **Fork** edin
2. **Feature branch** oluÅŸturun (`git checkout -b feature/NewFeature`)
3. **Commit** edin (`git commit -am 'Add new feature'`)
4. **Push** edin (`git push origin feature/NewFeature`)
5. **Pull Request** oluÅŸturun

### ğŸ’¡ KatkÄ± AlanlarÄ±

| ğŸš€ Ã–zellik | ğŸ“ AÃ§Ä±klama | ğŸ¯ Zorluk |    
|-----------|-------------|----------|    
| **Engel Sistemi** | Grid'e engeller ve rÃ¼zgar etkisi | ğŸŸ¡ Orta |    
| **Ã‡oklu Drone** | AynÄ± anda birden fazla drone | ğŸ”´ Zor |    
| **Deep Q-Learning** | Neural network tabanlÄ± Ã¶ÄŸrenme | ğŸ”´ Zor |    
| **3D GÃ¶rselleÅŸtirme** | 3D ortam | ğŸŸ¡ Orta |    
| **GerÃ§ek ZamanlÄ± Ä°statistikler** | Matplotlib entegrasyonu | ğŸŸ¢ Kolay |    
| **Ses Efektleri** | Drone sesleri ve geri bildirimler | ğŸŸ¢ Kolay |
---

<div align="center">
  <h3>â­ Projeyi beÄŸendiyseniz star vermeyi unutmayÄ±n! â­</h3>
  <p>Herhangi bir sorunuz varsa <a href="https://github.com/FerhatAkalan/DroneDeliverySystemQLearning/issues">issue aÃ§abilirsiniz</a>.</p>
  
  **ğŸš Happy Coding! ğŸš**
  
  <sub>Made with â¤ï¸ by Ferhat Akalan</sub>
</div>
