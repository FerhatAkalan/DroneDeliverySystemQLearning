| Language | [English](#english)  | [TÃ¼rkÃ§e](#tÃ¼rkÃ§e) |
|-----------|-------------|---------|

## <a name="english"></a>

# ğŸš Drone Delivery System with Q-Learning

<div align="center">
  <p><em>Intelligent Package Delivery System with Reinforcement Learning</em></p>
</div>

---

## ğŸ“– About the Project

This project is an intelligent drone simulator that optimizes urban package deliveries using the **Reinforcement Learning (Q-Learning)** algorithm. Drones pick up packages from the cargo depot and learn the most efficient routes to deliver them to multiple delivery points.

### ğŸ¯ Project Goals
- Simulate real-world logistics problems
- Demonstrate practical application of the Q-Learning algorithm
- Observe the learning process with an interactive visual interface
- Experiment with training parameters to achieve the best results

## âœ¨ Features

### ğŸ¤– Reinforcement Learning
- **Q-Learning Algorithm**: Drone learns optimal strategies
- **Epsilon-Greedy**: Balance between exploration and exploitation
- **Experience Replay**: Learning from past experiences
- **Adjustable hyperparameters**: Alpha, gamma, epsilon decay

### ğŸ® Interactive Simulation
- **Visual Grid Environment**: Customizable city map with 5x5 size
- **Real-Time Animation**: Takeoff, landing, and movement animations
- **Manual Play Mode**: Control the drone with keyboard (WASD/Arrow keys)
- **AI Demo Mode**: Watch the trained agent's performance

### ğŸ“Š Simulation Details
- ğŸŸ¢ **Cargo Depot**: Center where packages are picked up
- ğŸ”´ **Delivery Points**: Randomly placed target locations (1-3)
- ğŸ”µ **Drone**: Intelligent agent (battery, cargo status display)
- ğŸ”‹ **Battery Management**: Different energy costs for movement, takeoff, landing

### ğŸ’¾ Model Management
- **Save/Load Q-Table**: Store trained models
- **Training Statistics**: Track reward and steps per episode
- **Speed Settings**: Control training and simulation speeds

## ğŸ› ï¸ Technology Stack

| Technology | Description | Version |
|-----------|-------------|---------|
| ![Python](https://img.shields.io/badge/-Python-3776ab?style=flat&logo=python&logoColor=white) | Main programming language | 3.10+ |
| ![PyQt5](https://img.shields.io/badge/-PyQt5-41CD52?style=flat&logo=qt&logoColor=white) | GUI framework | 5.15+ |
| ![NumPy](https://img.shields.io/badge/-NumPy-013243?style=flat&logo=numpy&logoColor=white) | Numerical computations | Latest |

## ğŸš€ Installation

### Requirements
```bash
# Python 3.10 or higher is required
python --version
```

### 1. Clone the Project
```bash
git clone https://github.com/FerhatAkalan/DroneDeliverySystemQLearning.git
cd DroneDeliverySystemQLearning
```

### 2. Install Dependencies
```bash
pip install PyQt5 numpy
```

### 3. Start the Simulator
```bash
python drone_delivery_system_q_learning.py
```

## ğŸ¯ Usage

### ğŸ“ Model Training
1. **Set Parameters**:
   - Grid size (3x3 - 7x7)
   - Learning rate (Alpha): 0.01 - 1.0
   - Discount factor (Gamma): 0.1 - 0.999
   - Exploration rate (Epsilon): 0.1 - 1.0

2. **Select Training Mode**:
   - **Fast**: Fast training in visual interface
   - **Human**: Step-by-step visual tracking

3. **Start Training**: Click the "ğŸš€ Start Training" button

### ğŸ¤– AI Demo
1. After training, use the "ğŸ¤– Play with AI" button
2. Watch the trained drone's performance in real time
3. You can adjust the simulation speed

### ğŸ® Manual Control
1. Select "ğŸ§‘â€ğŸ’» Human Mode"
2. Keyboard controls:
   - **Move**: `WASD` or `â†‘â†“â†â†’` arrow keys
   - **Takeoff/Land**: `Space`
   - **Pick/Drop Cargo**: `E`

## ğŸ§  Q-Learning Algorithm

### ğŸ”„ Action Space
| Action | Description | Condition |
|--------|-------------|-----------|
| `0` â¬‡ï¸ | Move down | Drone must be flying |
| `1` â¡ï¸ | Move right | Drone must be flying |
| `2` â¬†ï¸ | Move up | Drone must be flying |
| `3` â¬…ï¸ | Move left | Drone must be flying |
| `4` ğŸ“¦ | Pick/Drop cargo | Drone must be on the ground |
| `5` ğŸ›«ğŸ›¬ | Takeoff/Land | Always |

### ğŸ† Reward System

#### âœ… Positive Rewards
- **Pick up cargo**: +50 points
- **Successful delivery**: +200 points
- **Task completion**: +200 + battery bonus
- **Approaching target**: +5 points
- **Correct action at correct position**: +10 points

#### âŒ Penalties
- **Invalid action**: -2 to -30 points
- **Battery depletion**: -100 points
- **Timeout**: -50 points

### ğŸ“ˆ State Representation
```python
state = (x, y, has_cargo, is_flying, delivery_status, battery_level, delivery_indices)
```

- `(x, y)`: Drone coordinates
- `has_cargo`: Cargo carrying status
- `is_flying`: Flight status
- `delivery_status`: Delivery completion status
- `battery_level`: Battery level (0-10)
- `delivery_indices`: Active delivery points

## ğŸ¥ Project Video
https://github.com/user-attachments/assets/dc8752a9-d821-4c75-901b-993b0077d4b4

## ğŸ”¬ Experimental Results

### ğŸ“Š Training Performance
- **Grid Size**: 5x5
- **Number of Episodes**: 50000
- **Average Reward**: ~450 points
- **Success Rate**: 85%+ (completing all deliveries)

### ğŸ“ˆ Learning Curve
As training progresses, drone performance increases significantly:
- First 1000 episodes: Random behavior
- 1000-3000 episodes: Learning basic strategy
- 3000+ episodes: Optimized route planning

## ğŸ¤ Contributing

If you want to contribute to this project:

1. **Fork** it
2. **Create a feature branch** (`git checkout -b feature/NewFeature`)
3. **Commit** (`git commit -am 'Add new feature'`)
4. **Push** (`git push origin feature/NewFeature`)
5. **Create a Pull Request**

### ğŸ’¡ Contribution Areas

| ğŸš€ Feature | ğŸ“ Description | ğŸ¯ Difficulty |
|-----------|---------------|--------------|
| **Obstacle System** | Obstacles and wind effect in grid | ğŸŸ¡ Medium |
| **Multi Drone** | Multiple drones at the same time | ğŸ”´ Hard |
| **Deep Q-Learning** | Neural network-based learning | ğŸ”´ Hard |
| **3D Visualization** | 3D environment | ğŸŸ¡ Medium |
| **Real-Time Statistics** | Matplotlib integration | ğŸŸ¢ Easy |
| **Sound Effects** | Drone sounds and feedback | ğŸŸ¢ Easy |

---

<div align="center">
  <h3>â­ If you like the project, don't forget to give a star! â­</h3>
  <p>If you have any questions, you can <a href="https://github.com/FerhatAkalan/DroneDeliverySystemQLearning/issues">open an issue</a>.</p>
  
  **ğŸš Happy Coding! ğŸš**
  
  <sub>Made with â¤ï¸ by Ferhat Akalan</sub>
</div>

## <a name="tÃ¼rkÃ§e"></a>

# ğŸš Q-Learning ile Drone Teslimat Sistemi

<div align="center">
  <p><em>PekiÅŸtirmeli Ã–ÄŸrenme ile AkÄ±llÄ± Paket Teslimat Sistemi</em></p>
</div>

---

## ğŸ“– Proje HakkÄ±nda

Bu proje, **PekiÅŸtirmeli Ã–ÄŸrenme (Q-Learning)** algoritmasÄ± kullanarak ÅŸehir iÃ§i paket teslimatlarÄ±nÄ± optimize eden akÄ±llÄ± bir dron simÃ¼latÃ¶rÃ¼dÃ¼r. Dronlar, kargo deposundan paketleri alÄ±p birden fazla teslimat noktasÄ±na en verimli rotalarÄ± Ã¶ÄŸrenerek ulaÅŸtÄ±rÄ±rlar.

### ğŸ¯ Proje Hedefleri
- GerÃ§ek dÃ¼nya lojistik problemlerini simÃ¼le etmek
- Q-Learning algoritmasÄ±nÄ±n pratik uygulamasÄ±nÄ± gÃ¶stermek  
- Ä°nteraktif gÃ¶rsel arayÃ¼z ile Ã¶ÄŸrenme sÃ¼recini gÃ¶zlemlemek
- EÄŸitim parametrelerini deneyimleyerek en iyi sonuÃ§larÄ± elde etmek          

## âœ¨ Ã–zellikler

### ğŸ¤– PekiÅŸtirmeli Ã–ÄŸrenme
- **Q-Learning AlgoritmasÄ±**: Dron optimal stratejileri Ã¶ÄŸrenir
- **Epsilon-Greedy**: KeÅŸif ve sÃ¶mÃ¼rÃ¼ dengesi
- **Experience Replay**: GeÃ§miÅŸ deneyimlerden Ã¶ÄŸrenme
- **Ayarlanabilir hiperparametreler**: Alpha, gamma, epsilon decay

### ğŸ® Ä°nteraktif SimÃ¼lasyon
- **GÃ¶rsel Grid Ortam**: 5x5 boyutlarÄ±nda Ã¶zelleÅŸtirilebilir ÅŸehir haritasÄ±
- **GerÃ§ek ZamanlÄ± Animasyon**: KalkÄ±ÅŸ, iniÅŸ ve hareket animasyonlarÄ±
- **Manuel Oynama Modu**: Klavye ile drone kontrolÃ¼ (WASD/Ok tuÅŸlarÄ±)
- **AI Demo Modu**: EÄŸitilmiÅŸ ajanÄ±n performansÄ±nÄ± izleme

### ğŸ“Š SimÃ¼lasyon DetaylarÄ±
- ğŸŸ¢ **Kargo Deposu**: Paketlerin alÄ±ndÄ±ÄŸÄ± merkez
- ğŸ”´ **Teslimat NoktalarÄ±**: Rastgele yerleÅŸtirilen hedef lokasyonlar (1-3 adet)
- ğŸ”µ **Drone**: AkÄ±llÄ± ajan (batarya, kargo durumu gÃ¶sterimi)
- ğŸ”‹ **Batarya YÃ¶netimi**: Hareket, kalkÄ±ÅŸ, iniÅŸ iÃ§in farklÄ± enerji maliyetleri

### ğŸ’¾ Model YÃ¶netimi
- **Q-Table Kaydetme/YÃ¼kleme**: EÄŸitilmiÅŸ modelleri saklama
- **EÄŸitim Ä°statistikleri**: BÃ¶lÃ¼m baÅŸÄ±na Ã¶dÃ¼l ve adÄ±m takibi
- **HÄ±z AyarlarÄ±**: EÄŸitim ve simÃ¼lasyon hÄ±zlarÄ±nÄ± kontrol etme

## ğŸ› ï¸ Teknoloji Stack

| Teknoloji | AÃ§Ä±klama | Versiyon |
|-----------|----------|----------|
| ![Python](https://img.shields.io/badge/-Python-3776ab?style=flat&logo=python&logoColor=white) | Ana programlama dili | 3.10+ |
| ![PyQt5](https://img.shields.io/badge/-PyQt5-41CD52?style=flat&logo=qt&logoColor=white) | GUI framework | 5.15+ |
| ![NumPy](https://img.shields.io/badge/-NumPy-013243?style=flat&logo=numpy&logoColor=white) | SayÄ±sal hesaplamalar | Latest |

## ğŸš€ Kurulum

### Gereksinimler
```bash
# Python 3.10 veya Ã¼zeri gereklidir
python --version
```

### 1. Projeyi KlonlayÄ±n
```bash
git clone https://github.com/FerhatAkalan/DroneDeliverySystemQLearning.git
cd DroneDeliverySystemQLearning
```

### 2. BaÄŸÄ±mlÄ±lÄ±klarÄ± YÃ¼kleyin
```bash
pip install PyQt5 numpy
```

### 3. SimÃ¼latÃ¶rÃ¼ BaÅŸlatÄ±n
```bash
python drone_delivery_system_q_learning.py
```

## ğŸ¯ KullanÄ±m

### ğŸ“ Model EÄŸitimi
1. **Parametreleri AyarlayÄ±n**:
   - Grid boyutu (3x3 - 7x7)
   - Learning rate (Alpha): 0.01 - 1.0
   - Discount factor (Gamma): 0.1 - 0.999
   - Exploration rate (Epsilon): 0.1 - 1.0

2. **EÄŸitim Modunu SeÃ§in**:
   - **Fast**: GÃ¶rsel arayÃ¼zde hÄ±zlÄ± eÄŸitim
   - **Human**: AdÄ±m adÄ±m gÃ¶rsel takip

3. **EÄŸitimi BaÅŸlatÄ±n**: "ğŸš€ EÄŸitimi BaÅŸlat" butonuna tÄ±klayÄ±n

### ğŸ¤– AI Demo
1. EÄŸitim tamamlandÄ±ktan sonra "ğŸ¤– AI ile Oyna" butonunu kullanÄ±n
2. EÄŸitilmiÅŸ dronun performansÄ±nÄ± gerÃ§ek zamanlÄ± izleyin
3. SimÃ¼lasyon hÄ±zÄ±nÄ± ayarlayabilirsiniz

### ğŸ® Manuel Kontrol
1. "ğŸ§‘â€ğŸ’» Human Modu" seÃ§in
2. Klavye kontrolleri:
   - **Hareket**: `WASD` veya `â†‘â†“â†â†’` ok tuÅŸlarÄ±
   - **KalkÄ±ÅŸ/Ä°niÅŸ**: `Space` (BoÅŸluk)
   - **Kargo Al/BÄ±rak**: `E`

## ğŸ§  Q-Learning AlgoritmasÄ±

### ğŸ”„ Eylem UzayÄ±
| Eylem | AÃ§Ä±klama | KoÅŸul |
|-------|----------|-------|
| `0` â¬‡ï¸ | AÅŸaÄŸÄ± hareket | Drone havada olmalÄ± |
| `1` â¡ï¸ | SaÄŸa hareket | Drone havada olmalÄ± |
| `2` â¬†ï¸ | YukarÄ± hareket | Drone havada olmalÄ± |
| `3` â¬…ï¸ | Sola hareket | Drone havada olmalÄ± |
| `4` ğŸ“¦ | Kargo al/bÄ±rak | Drone yerde olmalÄ± |
| `5` ğŸ›«ğŸ›¬ | KalkÄ±ÅŸ/Ä°niÅŸ | Her zaman |

### ğŸ† Ã–dÃ¼l Sistemi

#### âœ… Pozitif Ã–dÃ¼ller
- **Kargo alma**: +50 puan
- **BaÅŸarÄ±lÄ± teslimat**: +200 puan
- **GÃ¶rev tamamlama**: +200 + batarya bonusu
- **Hedefe yaklaÅŸma**: +5 puan
- **DoÄŸru konumda eylem**: +10 puan

#### âŒ Cezalar
- **GeÃ§ersiz eylem**: -2 ile -30 puan arasÄ±
- **Batarya bitimi**: -100 puan
- **Zaman aÅŸÄ±mÄ±**: -50 puan

### ğŸ“ˆ Durum TemsilÃ¯
```python
state = (x, y, has_cargo, is_flying, delivery_status, battery_level, delivery_indices)
```

- `(x, y)`: Drone koordinatlarÄ±
- `has_cargo`: Kargo taÅŸÄ±ma durumu
- `is_flying`: UÃ§uÅŸ durumu
- `delivery_status`: Teslimat tamamlanma durumu
- `battery_level`: Batarya seviyesi (0-10)
- `delivery_indices`: Aktif teslimat noktalarÄ±

## ğŸ¥ Proje Videosu
https://github.com/user-attachments/assets/dc8752a9-d821-4c75-901b-993b0077d4b4

## ğŸ”¬ Deneysel SonuÃ§lar

### ğŸ“Š EÄŸitim PerformansÄ±
- **Grid Boyutu**: 5x5
- **Episode SayÄ±sÄ±**: 50000
- **Ortalama Ã–dÃ¼l**: ~450 puan
- **BaÅŸarÄ± OranÄ±**: %85+ (tÃ¼m teslimatlarÄ± tamamlama)

### ğŸ“ˆ Ã–ÄŸrenme EÄŸrisi
EÄŸitim ilerledikÃ§e dronun performansÄ± belirgin ÅŸekilde artar:
- Ä°lk 1000 episode: Rastgele davranÄ±ÅŸ
- 1000-3000 episode: Temel strateji Ã¶ÄŸrenme
- 3000+ episode: Optimize edilmiÅŸ rota planlama

## ğŸ¤ KatkÄ±da Bulunma

Bu projeye katkÄ±da bulunmak istiyorsanÄ±z:

1. **Fork** edin
2. **Feature branch** oluÅŸturun (`git checkout -b feature/NewFeature`)
3. **Commit** edin (`git commit -am 'Add new feature'`)
4. **Push** edin (`git push origin feature/NewFeature`)
5. **Pull Request** oluÅŸturun

### ğŸ’¡ KatkÄ± AlanlarÄ±

| ğŸš€ Ã–zellik | ğŸ“ AÃ§Ä±klama | ğŸ¯ Zorluk |    
|-----------|-------------|----------|    
| **Engel Sistemi** | Grid'e engeller ve rÃ¼zgar etkisi | ğŸŸ¡ Orta |    
| **Ã‡oklu Drone** | AynÄ± anda birden fazla drone | ğŸ”´ Zor |    
| **Deep Q-Learning** | Neural network tabanlÄ± Ã¶ÄŸrenme | ğŸ”´ Zor |    
| **3D GÃ¶rselleÅŸtirme** | 3D ortam | ğŸŸ¡ Orta |    
| **GerÃ§ek ZamanlÄ± Ä°statistikler** | Matplotlib entegrasyonu | ğŸŸ¢ Kolay |    
| **Ses Efektleri** | Drone sesleri ve geri bildirimler | ğŸŸ¢ Kolay |
---

<div align="center">
  <h3>â­ Projeyi beÄŸendiyseniz star vermeyi unutmayÄ±n! â­</h3>
  <p>Herhangi bir sorunuz varsa <a href="https://github.com/FerhatAkalan/DroneDeliverySystemQLearning/issues">issue aÃ§abilirsiniz</a>.</p>
  
  **ğŸš Happy Coding! ğŸš**
  
  <sub>Made with â¤ï¸ by Ferhat Akalan</sub>
</div>
